{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urllib2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd7560bb98e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Generative-Adversarial-Networks/Triple-GAN/cifar10.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mone_hot_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Generative-Adversarial-Networks/Triple-GAN/download.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0murllib2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urllib2'"
     ]
    }
   ],
   "source": [
    "import cifar10\n",
    "from ops import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TripleGan(object):\n",
    "    \n",
    "    def discriminator(self,x,label,scope='discriminator',is_training=True,reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            x=dropout(x,0.2)  #to prevent overfitting, probability is kept at 0.2\n",
    "            y=reshape(label,[-1,1,1,10])#reshaping label to a 4-D vector\n",
    "            x=conv_concat(x,y)#concatenating y to x by reshaping y to same dimensions as x and adding ones wherever necessary \n",
    "        \n",
    "        #convolution 1\n",
    "        x=conv_layer(x,filter_size=32,stride=1,kernel=[3,3])#convolution with stride=1 \n",
    "        x=lrelu(x,0.2)#adding rectified linear unit to prevent vanishing derivatives\n",
    "        x=conv_concat(x,y)#concatenating y for conditional discriminator so that we can condition it on basis of output as well 32*128\n",
    "        x=conv_layer(x,filter_size=32,stride=2,kernel=[3,3])#strides of 2 as x has now doubled because of conactenating y to it 32*64\n",
    "        x=dropout(x,0.2)\n",
    "        x=lrelu(x,0.2)\n",
    "        \n",
    "        \n",
    "        #convolution 2\n",
    "        x=conv_layer(x,filter_size=64,stride=1,kernel=[3,3])\n",
    "        x=lrelu(x,0.2)\n",
    "        x=conv_concat(x,y)\n",
    "        x=conv_layer(x,filter_size=64,stride=2,kernel=[3,3])\n",
    "        x=dropout(x,0.2)\n",
    "        x=lrelu(x,0.2) \n",
    "        \n",
    "        \n",
    "        #convolution 3\n",
    "        x=conv_layer(x,filter_size=64,stride=1,kernel=[3,3])\n",
    "        x=lrelu(x,0.2)\n",
    "        x=conv_concat(x,y)\n",
    "        x=conv_layer(x,filter_size=64,stride=2,kernel=[3,3])\n",
    "        x=lrelu(x,0.2) \n",
    "        \n",
    "        #FC layers\n",
    "        x=GAP(x)#global average pooling layer, used to prevent overfitting reduces dimensions of form h*w*d to form 1*1*d by taking averages of h and w values\n",
    "        x=flatten(x)#flattening to a 1-d array\n",
    "        x=concat(x,label)#concatenation of labels to the output after all convolution to the flattened layer,1st fully conneceted layer\n",
    "        logit=linear(x,unit=1)\n",
    "        output=sigmoid(logit)#activation function\n",
    "        \n",
    "        return output,logit,x\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generator(self, z, y, scope='generator', is_training=True, reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=reuse) :\n",
    "\n",
    "            x = concat([z, y]) # mlp_concat\n",
    "\n",
    "            x = relu(linear(x, unit=512*4*4, layer_name=scope+'_linear1'))\n",
    "            x = batch_norm(x, is_training=is_training, scope=scope+'_batch1')\n",
    "\n",
    "            x = tf.reshape(x, shape=[-1, 4, 4, 512])\n",
    "            y = tf.reshape(y, [-1, 1, 1, self.y_dim])\n",
    "            x = conv_concat(x,y)\n",
    "\n",
    "            x = relu(deconv_layer(x, filter_size=256, kernel=[5,5], stride=2, layer_name=scope+'_deconv1'))\n",
    "            x = batch_norm(x, is_training=is_training, scope=scope+'_batch2')\n",
    "            x = conv_concat(x,y)\n",
    "\n",
    "            x = relu(deconv_layer(x, filter_size=128, kernel=[5,5], stride=2, layer_name=scope+'_deconv2'))\n",
    "            x = batch_norm(x, is_training=is_training, scope=scope+'_batch3')\n",
    "            x = conv_concat(x,y)\n",
    "\n",
    "            x = tanh(deconv_layer(x, filter_size=3, kernel=[5,5], stride=2, wn=False, layer_name=scope+'deconv3'))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def classifier(self, x, scope='classifier', is_training=True, reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=reuse) :\n",
    "            x = gaussian_noise_layer(x) # default = 0.15\n",
    "            x = lrelu(conv_layer(x, filter_size=128, kernel=[3,3], layer_name=scope+'_conv1'))\n",
    "            x = lrelu(conv_layer(x, filter_size=128, kernel=[3,3], layer_name=scope+'_conv2'))\n",
    "            x = lrelu(conv_layer(x, filter_size=128, kernel=[3,3], layer_name=scope+'_conv3'))\n",
    "\n",
    "            x = max_pooling(x, kernel=[2,2], stride=2)\n",
    "            x = dropout(x, rate=0.5, is_training=is_training)\n",
    "\n",
    "            x = lrelu(conv_layer(x, filter_size=256, kernel=[3,3], layer_name=scope+'_conv4'))\n",
    "            x = lrelu(conv_layer(x, filter_size=256, kernel=[3,3], layer_name=scope+'_conv5'))\n",
    "            x = lrelu(conv_layer(x, filter_size=256, kernel=[3,3], layer_name=scope+'_conv6'))\n",
    "\n",
    "            x = max_pooling(x, kernel=[2,2], stride=2)\n",
    "            x = dropout(x, rate=0.5, is_training=is_training)\n",
    "\n",
    "            x = lrelu(conv_layer(x, filter_size=512, kernel=[3,3], layer_name=scope+'_conv7'))\n",
    "            x = nin(x, unit=256, layer_name=scope+'_nin1')\n",
    "            x = nin(x, unit=128, layer_name=scope+'_nin2')\n",
    "\n",
    "            x = GAP(x)\n",
    "            x = flatten(x)\n",
    "            x = linear(x, unit=10, layer_name=scope+'_linear1')\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
